{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_classes = ['buoys', 'harbour', 'human', 'large_commercial_vessel', 'leisure_craft', 'sailboats', 'small_medium_fishing_boat']\n",
    "num_classes = len(object_classes)\n",
    "\n",
    "data_path = r'C:\\DTU\\master_thesis\\fsl\\Object-classification-with-few-shot-learning\\data\\raw\\updated_ds\\sailboats'\n",
    "\n",
    "model_name = \"resnet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of buoys images deleted is:  0\n",
      "The number of harbour images deleted is:  0\n",
      "The number of human images deleted is:  0\n",
      "The number of large_commercial_vessel images deleted is:  0\n",
      "The number of leisure_craft images deleted is:  0\n",
      "The number of sailboats images deleted is:  0\n",
      "The number of small_medium_fishing_boat images deleted is:  0\n"
     ]
    }
   ],
   "source": [
    "#Remove small images with one of the dimensions lesser than 16 pixels\n",
    "\n",
    "for object_class in object_classes:\n",
    "    num_deleted_images = 0\n",
    "    data_path = os.path.join('C:\\\\DTU\\\\master_thesis\\\\fsl\\\\Object-classification-with-few-shot-learning\\\\data\\\\raw\\\\updated_ds', object_class)\n",
    "    for (root, dirs, files) in os.walk(data_path, topdown = True):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            with Image.open(file_path) as img:\n",
    "                img_size = img.size\n",
    "            if img_size[0] < 16 or img_size[1] < 16:\n",
    "                os.remove(file_path)\n",
    "                num_deleted_images += 1\n",
    "    print(f'The number of {object_class} images deleted is: ', num_deleted_images)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaritimeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir=\"\", transform=transforms) -> None:\n",
    "        self.dataset = datasets.ImageFolder(root=root_dir)\n",
    "        self.transform = transform\n",
    "        self.paths, self.labels = zip(*self.dataset.samples)\n",
    "        self.classes = self.dataset.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, target = self.paths[index], self.labels[index]\n",
    "\n",
    "        with Image.open(path) as img:\n",
    "\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "        return img, target, index, path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "\n",
    "data_dir = r'C:\\DTU\\master_thesis\\fsl\\Object-classification-with-few-shot-learning\\data\\raw\\updated_ds'\n",
    "\n",
    "complete_dataset = MaritimeDataset(root_dir = data_dir,\n",
    "                                    transform = transforms.Compose([\n",
    "                                        transforms.Resize(image_size),\n",
    "                                        transforms.CenterCrop(image_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.RandomHorizontalFlip()\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splittin the data into train and test sets\n",
    "\n",
    "train_length = int(0.7* len(complete_dataset))\n",
    "\n",
    "test_length = len(complete_dataset) - train_length\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(complete_dataset, (train_length, test_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1504/1504 [00:27<00:00, 53.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the dataset is tensor([0.4609, 0.4467, 0.4413])\n",
      "The standard deviation of the dataset is tensor([0.1314, 0.1239, 0.1198])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def mean_and_std():\n",
    "    \"\"\"This function calculates the mean and standard deviation of the dataset\"\"\"\n",
    "\n",
    "    dataloader = DataLoader(complete_dataset, shuffle=False, batch_size=12)\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    nb_samples = 0.0\n",
    "\n",
    "    for images, _, _, _ in tqdm(dataloader):\n",
    "        batch_samples = images.size(0)\n",
    "        data = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std\n",
    "\n",
    "mean, std = mean_and_std()\n",
    "\n",
    "print(f'The mean of the dataset is', mean)\n",
    "print(f'The standard deviation of the dataset is', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x18b52f69490>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 6\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(complete_dataset.classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 1\n",
    "# steps = 0\n",
    "# running_loss = 0\n",
    "# print_every = 10\n",
    "# train_losses, test_losses = [], []\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#     for inputs, labels in train_dataloader:\n",
    "#         steps += 1\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         opt.zero_grad()\n",
    "#         logps = model.forward(inputs)\n",
    "#         loss = criterion(logps, labels)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         if steps % print_every == 0:\n",
    "#             test_loss = 0\n",
    "#             accuracy = 0\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, labels in tqdm(test_dataloader):\n",
    "#                     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                     logps = model.forward(inputs)\n",
    "#                     batch_loss = criterion(logps, labels)\n",
    "#                     test_loss += batch_loss.item()\n",
    "                    \n",
    "#                     ps = torch.exp(logps)\n",
    "#                     top_p, top_class = ps.topk(1, dim=1)\n",
    "#                     equals = top_class == labels.view(*top_class.shape)\n",
    "#                     accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "#             train_losses.append(running_loss/len(train_dataloader))\n",
    "#             test_losses.append(test_loss/len(test_dataloader))                    \n",
    "#             print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "#                   f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "#                   f\"Test loss: {test_loss/len(test_dataloader):.3f}.. \"\n",
    "#                   f\"Test accuracy: {accuracy/len(test_dataloader):.3f}\")\n",
    "#             running_loss = 0\n",
    "#             model.train()\n",
    "# torch.save(model, 'maritimemodelv1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convolutional_network = models.resnet18(pretrained=False)\n",
    "# convolutional_network.fc = nn.Flatten()\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# for param in convolutional_network.parameters():\n",
    "#     param.requires_grad = True\n",
    "# device = torch.device(\"cuda\")\n",
    "# print('1')\n",
    "# def train(model, train_dataloader, criterion, optimizer, epochs = 5):\n",
    "#     print('2')\n",
    "#     train_loss =[]\n",
    "#     for e in tqdm(range(epochs)):\n",
    "#         print('3')\n",
    "#         running_loss =0\n",
    "#         for images, labels in tqdm(train_dataloader):\n",
    "#             print('4')\n",
    "#             inputs, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             img = model(inputs)\n",
    "            \n",
    "#             loss = criterion(img, labels)\n",
    "#             running_loss+=loss\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         print(\"Epoch : {}/{}..\".format(e+1,epochs),\n",
    "#          \"Training Loss: {:.6f}\".format(running_loss/len(train_dataloader))) \n",
    "#         train_loss.append(running_loss)\n",
    "#     #plt.plot(train_loss,label=\"Training Loss\")\n",
    "#     #plt.show() \n",
    "#     filename_pth = 'model_resnet18_fsl.pth'\n",
    "#     torch.save(model.state_dict(), filename_pth)\n",
    "\n",
    "# def run():\n",
    "#     torch.multiprocessing.freeze_support()\n",
    "#     print('loop')\n",
    "\n",
    "# epochs = 5\n",
    "# convolutional_network.train()\n",
    "# optimizer = optim.Adam(convolutional_network.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss()    \n",
    "# train(convolutional_network,train_dataloader,criterion, optimizer, epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12628\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1579 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(train_dataloader.dataset):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "857b68075c8fbe544597e4511b0939b52ebf355c2760c57766b72c64e6348539"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
